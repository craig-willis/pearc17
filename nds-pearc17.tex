\documentclass{sig-alternate}
\usepackage{verbatim}
\usepackage{array}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{multirow}
\setcounter{secnumdepth}{5}
\usepackage{pdfpages}
\usepackage{url}

\newcommand{\argmax}{\arg\!\max} 
\newtheorem{definition}{Definition}
\begin{document}
\sloppy
\numberofauthors{2}

\author{
Craig Willis$^{1,3}$, Mike Lambert$^{1,3}$, Kenton McHenry$^{1,3}$, and Christine Kirkpatrick$^{2,3}$\\
     \affaddr{$^1$National Center for Supercomputing Applications}\\     
     \affaddr{$^2$San Diego Supercomputer Center}\\     
     \affaddr{$^3$National Data Service}\\     
     \email{\{willis8, lambert8, mchenry\}@illinois.edu, christine@sdsc.edu}
}
\conferenceinfo{PEARC}{'2017 New Orleans}

\title{Container-based Analysis Environments for Low-Barrier Access to Research Data}

\maketitle
\begin{abstract}

The growing size of high-value sensor-born or computationally derived scientific datasets are pushing the boundaries of traditional models of data access and discovery. Due to their size, these datasets are often only accessible through the systems on which they were created. Access for scientific exploration and reproducibility is limited to file transfer or by applying for access to the systems used to store or generate the original data, which is often infeasible. There is a growing trend toward providing access to large-scale research datasets in-place via container-based analysis environments. This paper describes the National Data Service (NDS) Labs Workbench platform and DataDNS initiative. The Labs Workbench platform is designed to provide scalable and low-barrier access to research data via container-based services. The DataDNS effort is a new initiative designed to enable discovery, access, and in-place analysis for large-scale data, providing a suite of interoperable services to enable researchers, as well as the tools they are most familiar with, to access and analyze these datasets where they reside.

\end{abstract}

% A category with the (minimum) three required fields
\category{H.3.3}{}{}

%\terms{}
\keywords{}

\section{Introduction}

Sensor-based, research-computing, and high-performance computing systems now produce massive amounts of data.  Traditional data publishing services, such as community and institutional repositories, are not equipped to handle very large research datasets.  Increasingly, researchers are leaving their data on research computing infrastructure or turning to cloud-based services to facilitate sharing and re-use. However, research-computing and HPC centers are typically not prepared to support long-term storage and access, as is often required by publishers, further disconnecting these research products from traditional discovery methods. New models of in-place publishing are needed to connect research computing and research data publishing infrastructure to support discovery and access for re-use and reproducibility.

Institutional and community repositories are beginning to support ``remote'' data publishing.  With this approach, researchers are responsible for arranging data storage with best-effort preservation and datasets are effectively published in-place. Researchers provide the repository with descriptive metadata about the datasets including methods of access and are assigned a digital object identifier (DOI).  Under this model, users can discover these datasets and information about how to access them via traditional discovery mechanisms. 

Existing approaches to providing access to these hosted datasets are inefficient and often ineffective.  Typically, research-computing infrastructure has supported two basic models of data access: transfer and direct access to the hosting system.  Transfer services, such as Globus Online, enable users to access these datasets by transferring them to local systems via GridFTP.  However, in many cases, the datasets are too large to move or copy. Researchers can apply for access to the systems used to store and generate the original data, but access is often restricted and the application process involved and time consuming.

Container-based analysis environments are emerging as a mechanism to provide low-barrier access to research data in-place.  Using container technology such as Docker, projects provide access to large datasets through custom analysis environments, such as Jupyter notebooks or Rstudio.  In these systems, remote users are able to register for an account via web-based interfaces that allow them to launch specialized, resource-constrained analysis environments to explore data in-place. Examples includes yt Hub \cite{smith2011}, SciServer \cite{Medvedev:2016:SCB:2949689.2949700}, and the TERRA-REF Analysis Workbench \cite{willis_craig_2017_580057}.

This paper describes two initiatives of the National Data Service (NDS) to facilitate in-place access to large research datasets. The Labs Workbench platform, used by the ARPAE TERRA-REF project, is designed to support exposing research data via customizable container-based analysis environments.  The DataDNS initiative is intended to connect various container-based analysis systems to the traditional publishing and discovery platforms to enable discovery, access, and analysis of datasets where they reside.


%\item There are lots of examples of low-barrier access being provided via Docker containers (yt.hub, SciServer, Whole Tale, Galaxy Portal, TERRA-REF, etc).
%\item Amazon public datasets
%\end{enumerate}

%Skyport
%Gerlach:2014:SCE:2689676.2689680
%http://dx.doi.org/10.1109/DataCloud.2014.6

This paper is organized as follows.  Section 2 provides a description of container-based analysis environments.  In Section 3 we describe the NDS Labs Workbench system and specifically how it's being used for the ARPAE TERRA-REF project, followed by a description of the NDS DataDNS initiative in Section 4 and next steps in Section 5.

%\section{Research in the Cloud}
%Space permitting, we can talk about the cloud-computing trend and services like Amazon Public Datasets.

% https://scholar.google.com/scholar?hl=en&q=amazon+public+datasets&btnG=&as_sdt=1%2C14&as_sdtp=

\section{Container-based analysis environments}

Container technology is increasingly used in research computing as an alternative to hypervisor-based virtual machines for the packaging, deployment, and execution of software. Containers are considered to be more resource-efficient and provide a clear and light-weight abstraction for packaging and increasingly for the preservation of research software \cite{Meng2015137}.  Because of this, container management platforms such as Docker\footnote{http://www.docker.com} and rkt\footnote{https://coreos.com/rkt} have achieved widespread adoption. The reader can refer to more detailed analysis of container technology in \cite{Soltesz:2007:COS:1272998.1273025,7095802,7036275}.

\emph{Container-based analysis environments} refers to systems that leverage container technology for the packaging and execution of interactive scientific research software. Containers are currently used in a variety of systems providing interactive and non-interactive access to research data. Systems such as yt Hub \cite{smith2011}, SciServer \cite{Medvedev:2016:SCB:2949689.2949700}, Whole Tale, and the TERRA-REF Analysis Workbench \cite{willis_craig_2017_580057} provide interactive containerized environments based on software including Jupyter \cite{kluyver2016jupyter}, RStudio \cite{Rstudio2015}, and MatLab. Other systems, such as Cyverse and SciPort\cite{Gerlach:2014:SCE:2689676.2689680}, leverage containers for the management and execution of scientific workflows. We refer to these non-interactive environments as \emph{container-based execution environments}, which are more likely to fit into batch-scheduling infrastructure.  Increasingly, research systems developers are seeing the need to support the computational research lifecycle from preliminary exploration through development and execution either on dedicated cloud-based or HPC systems.

\section{Labs Workbench}

Labs Workbench is an open-source platform developed by the National Data Service Consortium to facilitate sharing, discovery, evaluation, and development of research data management and analysis tools. The platform leverages Docker containers and the Kubernetes container orchestration framework to provide turn-key access to community developed tools. 
The Labs Workbench system includes the following features:
\begin{enumerate}
\itemsep-0.2em
\item Scalable container orchestration via Kubernetes
\item Catalog of community-contributed tools
\item Ability to import custom tools and personal catalogs
\item Authentication
\item Logging and monitoring
\item Shared filesystem via GlusterFS
\end{enumerate}

Labs Workbench has been effectively used in classroom and workshop environments to provide consistent, web-based access to applications. In early 2017, the Labs Workbench was deployed by the ARPAE TERRA-REF project to provide customized interactive analysis environments for the TERRA-REF reference dataset. 

\section{Use Case: TERRA-REF}

The ARPA-E TERRA program is focused on cutting-edge techniques for the improvement of biofuel crops in part through the creation and publication of a large public reference dataset, TERRA-REF, and associated compute pipeline\cite{arpae2015}. The TERRA-REF data storage and computing system will provide researchers with access to over 2PB of raw sensor and derived data hosted on the NSF ROGER system and made available via Globus, Clowder, BETYdb, and the Labs Workbench. Researchers can also apply for accounts on the ROGER system directly for access via batch-processing. The TERRA-REF team is working withe the Dryad data repository\footnote{https://www.datadryad.org} to publish the remotely-hosted reference dataset.

In early 2017, the TERRA-REF team used the Labs Workbench platform to host a workshop, enabling ~50 participants to explore the reference dataset using domain-specific Jupyter, Rstudio and other interactive environments. Shortly after, an instance of Labs Workbench, named the TERRA-REF Analysis Workbench, was deployed on the NCSA Nebula OpenStack system to provide ongoing access to the TERRA-REF data for project contributors. Custom containers were created based on Jupyter, Rstudio, Cloud9, and Wetty to include dependencies required to access and use the TERRA-REF data including NetCDF/NCO and OpenCV libraries.  Additional containers were created to support system development, including a Python IDE for Clowder extractors and PostgresSQL Studioto provide access to the BETYdb PostGIS database.

The Labs Workbench platform was later used to support the two-week PI4 Computational Mathematics Bootcamp, an NSF funded program for graduate students to gain computational skills needed in scientific and engineering research labs. Students were provided with access to the TERRA-REF containers and data for a series of tutorials. 


The TERRA-REF Analysis Workbench presents an interesting case. The same system is used to provide access to data products for exploration and reuse; system development; as well as education and training.

\subsection{System architecture}

The Labs Workbench platform is based on the Kubernetes\footnote{http://www.kubernetes.io} container orchestration framework, deployed using the OpenStack\footnote{http://www.openstack.org} virtualization platform. Figure \ref{fig.arch} illustrates the basic architecture. First, a set of virtual machines and volumes is provisioned via the OpenStack API. Second, Kubernetes core services (controller, kubelet, and etcd) are deployed on each node. Third, Labs Workbench core and system services are deployed via Kubernetes. Labs Workbench core services include the the Nginx ingress load-balancer (nginx-ilb), which provides authenticated access to running containers in the cluster, as well as a thin REST API server (ndslabs-apiserver) an Angular user interface (ndslabs-webui). System services include standard logging, monitoring and alerting (LMA) tools such as Kibana/ElasticSaerch, Grafana/Heapster, and Nagios.  The system includes a private Docker registry for image caching.  Via Labs Workbench, users can launch a variety of Docker-based applications including but not limited to Jupyter and RStudio environments. The service catalog itself is a set of customizable Javascript Object Notation (JSON) objects currently stored in Github\footnote{https://www.github.com/nds-org/ndslabs-specs}. The Labs Workbench platform uses Gluster\footnote{https://www.gluster.org/} to provide shared storage between nodes and containers. Additional shared network volumes can also be mounted via other network services, such as NFS.

\begin{figure}[!ht]
\includegraphics[width=8.75cm]{architecture.png}
\caption{Labs Workbench systems architecture}
\label{fig.arch}
\end{figure}

The Labs Workbench platform is focused primarily on interactive, web-based applications.  Complex applications with multiple dependencies are supported. Support is available for command-line applications via web-based IDEs or terminal emulators.  

\section{DataDNS}

The Labs Workbench is just one example of an emerging trend to provide access to research data via cloud and container-based environments.  Other examples include yt Hub \cite{smith2011}, an innovator in this area, that uses the Girder data management platform\footnote{https://github.com/girder/girder} and custom Jupyter analysis environments to enable access to data for a number of fields including astronomy and cosmology. The yt Hub architecture is currently being adapted to support the Whole Tale project and the Renaissance Simulations Laboratory (RSL), providing access to the Renaissance Simulations data\cite{2041-8205-807-1-L12}.  Similarly, the SciServer Compute system provides access to astronomy, materials science, turbulence, and earth science datasets via domain-specific Rstudio, MatLab and Jupyter containers \cite{Medvedev:2016:SCB:2949689.2949700}.  SciServer also offers a container-based job scheduling component not available in these other systems.  The DataDNS initiative is designed in part to leverage these and other heterogeneous cloud- and container-based computing platforms to enable discovery, access, and in-place analysis of large-scale data. 

DataDNS is intended to connect traditional research data publishing infrastructure to research computing infrastructure. The goal is to enable users to not only discover these datasets, but also to enable access for in-place analysis. DataDNS will provide an active registry and resolution service to connect researchers to locations with access, analysis, and compute capabilities.  

Through DataDNS, researchers will register datasets to enable access in-place. Datasets will include information about associated capabilities, such as file transfer or container-based, cloud-based or batch compute. Researchers will not only be able to find the data, but also access it and perform analysis, when possible.   

\section{Conclusions and Next Steps}

Upcoming features:
\begin{enumerate}
\item Single sign-on
\item Simplified installation
\item Commercial cloud support
\item Data sharing within the system
\item Mounting external data into the system
\item Job execution
\end{enumerate}

\section{Acknowledgments}
This work was supported in part by X. Any opinions, findings, conclusions, or recommendations expressed are those of the authors and do not necessarily reflect the views of the X.

\bibliographystyle{abbrv}
\bibliography{containers}  


\end{document}
